




#' Read csv lazily
#'
#' @param path string, Path to a file
#' @param sep Single char to use as delimiter in the file.
#' @param has_header bool, indicate if the first row of dataset is a header or not.
#'  If set to False, column names will be autogenerated in the following format:
#'  column_x, with x being an enumeration over every column in the dataset starting at 1.
#' @param ignore_errors bool, try to keep reading lines if some lines yield errors. First try
#' infer_schema_length=0 to read all columns as pl.Utf8 to check which values might cause
#' an issue.
#' @param skip_rows integer, Start reading after skip_rows lines. The header will be parsed
#' at this offset.
#' @param n_rows int (NULL is disable),Stop reading from CSV file after reading n_rows.
#' @param cache bool, cache the result after reading.
#' @param overwrite_dtype (NULL is disable) named list of dtypes OR dtype-names, where name points
#' to a column. Can overwrite dtypes during inference.
#' Supported types so far are:
#'  name | alias | polars side dtype
#' "Boolean" | "logical" => DataType::Boolean,
#' "Float32" | "double" => DataType::Float32,
#' "Float64" | "float64" => DataType::Float64,
#' "Int32" | "integer" => DataType::Int32,
#' "Int64" | "integer64" => DataType::Int64,
#' "Utf8" | "character" => DataType::Utf8,
#'
#' @param low_memory bool, reduce memory usage in expense of performance
#' @param comment_char (NULL is disable) Single byte character that indicates the start of a comment line,
#' for instance #.
#' @param quote_char (NULL is disable) Single byte character used for csv quoting, default = ". Set to None
#' to turn off special handling and escaping of quotes.
#' @param null_values  (NULL is disable) Values to interpret as null values. You can provide a
#' String : All values equal to this string will be null.
#' Unnamed char vector: A null value per column.
#' Named char vector.  A mapping from (names)column to a null value string(values).
#'
#' @param infer_schema_length (NULL is disable) Maximum number of lines to read to infer schema. If set to 0, all columns will
#' be read as pl.Utf8. If set to None, a full table scan will be done (slow).
#' @param rechunk bool Reallocate to contiguous memory when all chunks/ files are parsed.
#' @param skip_rows_after_header bool Skip this number of rows when the header is parsed.
#' @param encoding either "utf8" or "utf8-lossy". Lossy means that invalid utf8 values are replaced with ï¿½ characters.
#' @param row_count_name String(NULL is disable), name of a added row count column
#' @param row_count_offset integer, Offset to start the row_count column (only used if the name is set).
#' @param parse_dates bool Try to automatically parse dates. If this does not succeed, the column remains of data type pl.Utf8.
#'
#' @return lazyframe
#'
#' @importFrom rlang is_string
#'
#' @details  Read a file from path into a polars lazy frame. Not yet supporting eol_char and with_column_names
#'
#' @examples
#' write.csv(iris,"my.csv")
#' lazy_frame = minipolars:::lazy_csv_reader(path="my.csv")
#' lazyframe$collect()
lazy_csv_reader = function(
  path,
  sep = ",",
  has_header = TRUE,
  ignore_errors = FALSE,
  skip_rows = 0,
  n_rows = NULL,
  cache = FALSE,
  overwrite_dtype = NULL,  #minipolars:::DataTypeVector$new()$print()
  low_memory = FALSE,
  comment_char = NULL,
  quote_char = '"',
  null_values = NULL,
  infer_schema_length = 100,
  rechunk = TRUE,
  skip_rows_after_header = 0,
  encoding = "utf8",
  row_count_name = NULL,
  row_count_offset = 0,
  parse_dates = FALSE
) {

  #capture all args and modify some to match lower level function
  args = as.list(environment())

  #overwrite_dtype: convert named list of DataType's to DataTypeVector obj
  if(!is.null(args$overwrite_dtype)) {
    owdtype = args$overwrite_dtype
    ##TODO support also unnamed list, like will be interpreted as positional dtypes args by polars.
    if( !is.list(owdtype) || !rlang::is_named(owdtype)) {
      abort("could not interpret overwrite_dtype, must be a named list of DataTypes")
    }
    datatype_vector = minipolars:::DataTypeVector$new() #mutable
    mapply(
      name = names(owdtype),
      type = unname(owdtype),
      FUN = function(name, type) {

        #convert possible string to datatype
        if(is_string(type)) {
          type = minipolars:::DataType$new(type)
        }
        if(!inherits(type,"DataType")) {
          abort("arg overwrite_dtype must be a named list of dtypes or dtype names")
        }
        datatype_vector$push(name,type)
      }
    )
    args$overwrite_dtype = datatype_vector
  }


  #null_values: convert string or un/named  char vec into RNullValues obj
  if(!is.null(args$null_values)) {
    nullvals = args$null_values
    ##TODO support also unnamed list, like will be interpreted as positional dtypes args by polars.
    RNullValues = function() {

      #one string is used as one NULL marker for all columns
      if(is_string(nullvals)) {
        return(minipolars:::RNullValues$new_all_columns(nullvals))
      }

      #many unnamed strings(char vec) is used one mark for each column
      if(is.character(nullvals) && !is_named(nullvals)) {
        return(RNullValues = minipolars:::RNullValues$new_columns(nullvals))
      }

      #named char vec is used as column(name) marker(value) pairs
      if(is.character(nullvals) && is_named(nullvals)) {
        return(minipolars:::RNullValues$new_named(null_values))
      }

      abort("null_values arg must be a string OR unamed char vec OR named char vec")
    }()

    args$null_values = RNullValues
  }

  ##call low level function with args
  minipolars:::check_no_missing_args(minipolars:::rlazy_csv_reader,args)
  do.call(minipolars:::rlazy_csv_reader,args)
}
#' Read csv to DataFrame
#' @rdname lazy_csv_reader
#' @return DataFrame
#' @export
csv_reader = function(...) {
  minipolars:::lazy_csv_reader(...)$collect()
}


#' high level csv_reader, will download if path is url
#'
#' @param path file or url
#' @param ...
#'
#' @return polars_DataFrame or polars_lazy_DataFrame
#' @export
#'
#' @examples df = read_csv("https://j.mp/iriscsv")
read_csv_ = function(path, lazy= FALSE, reuse_downloaded = TRUE,  ...) {

  # check if path is a existing file, or else try if url to download
  if(!file.exists(path)) {
    con = NULL

    #check if possible to open url connection
    assumed_schemas = c("","https://","http://","ftp://")
    for(i_schema in assumed_schemas) {
      if(!is.null(con)) break
      actual_url = paste0(i_schema,path)
      suppressWarnings(
        tryCatch(
          {con = url(actual_url,open = "rt")},
          error = function(e) {}
        )
      )
    }

    #try download file if valid url
    if(!is.null(con)) {
      close(con)
      tmp_file = paste0(tempdir(),"/",make.names(actual_url))
      if( isFALSE(reuse_downloaded) || isFALSE(file.exists(tmp_file))) {
        download.file(url = actual_url, destfile = tmp_file)
        message(paste("tmp file placed in \n",tmp_file))
      }

      path = tmp_file #redirect path to tmp downloaded file
    } else {

      #do nothing let path fail on rust side
    }

  }

  #read csv
  if(lazy) {
    lazy_csv_reader(path,...)
  } else {
    csv_reader(path,...)
  }

}


