% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/output-batches.R
\name{lazyframe__sink_batches}
\alias{lazyframe__sink_batches}
\alias{lazyframe__lazy_sink_batches}
\title{Evaluate the query and call a user-defined function for every ready batch}
\usage{
lazyframe__sink_batches(
  lambda,
  ...,
  chunk_size = NULL,
  maintain_order = TRUE,
  engine = c("auto", "in-memory", "streaming")
)

lazyframe__lazy_sink_batches(
  lambda,
  ...,
  chunk_size = NULL,
  maintain_order = TRUE
)
}
\arguments{
\item{lambda}{A function that will receive a \link{DataFrame} as the first argument and
called for side effects (e.g., writing to a file).
If the function returns \code{TRUE} and using the streaming engine,
this signals that no more results are needed, allowing for early stopping.}

\item{...}{These dots are for future extensions and must be empty.}

\item{chunk_size}{A positive integer or \code{NULL} (default).
The number of rows that are buffered before the callback is called.}

\item{maintain_order}{Maintain the order in which data is processed. Setting
this to \code{FALSE} will be slightly faster.}

\item{engine}{The engine name to use for processing the query.
One of the followings:
\itemize{
\item \code{"auto"} (default): Select the engine automatically.
The \code{"in-memory"} engine will be selected for most cases.
\item \code{"in-memory"}: Use the in-memory engine.
\item \code{"streaming"}: \ifelse{html}{\href{https://lifecycle.r-lib.org/articles/stages.html#experimental}{\figure{lifecycle-experimental.svg}{options: alt='[Experimental]'}}}{\strong{[Experimental]}} Use the (new) streaming engine.
}}
}
\value{
\itemize{
\item \verb{<lazyframe>$sink_batches()} returns \code{NULL} invisibly.
\item \verb{<lazyframe>$lazy_sink_batches()} returns a new \link{LazyFrame}.
}
}
\description{
\ifelse{html}{\href{https://lifecycle.r-lib.org/articles/stages.html#experimental}{\figure{lifecycle-experimental.svg}{options: alt='[Experimental]'}}}{\strong{[Experimental]}}
This allows streaming results that are larger than RAM in certain cases.
Note that this method is much slower than native sinks.
Only use it if you cannot implement your logic otherwise.
}
\details{
\verb{<lazyframe>$sink_batches()} is a shortcut for \verb{<lazyframe>$lazy_sink_batches()$collect()}.
}
\examples{
lf <- as_polars_lf(mtcars)

# Each batch is a Polars DataFrame
lf$sink_batches(\(df) print(df), chunk_size = 10)

# We can stop reading the batches by returning `TRUE`:
lf$sort("cyl")$sink_batches(
  \(df) {
    print(df)

    # We want to stop if this condition is respected:
    max(df[["cyl"]])$to_r_vector() > 4
  },
  chunk_size = 10
)

# One usecase for this function is to export larger-than-RAM data to file
# formats for which polars doesn't provide a writer out of the box.
# The example below writes a LazyFrame by batches to a CSV file for the
# sake of the example, but one could replace `write.csv()` by
# `haven::write_dta()`, `saveRDS()`, or other functions.
#
# Note that if `chunk_size` is missing, then Polars tries to compute it
# automatically. However, depending on the characteristics of the data (for
# instance very long string elements), this can lead to out-of-memory errors.
# It is therefore recommended to set `chunk_size` manually.

output_dir <- withr::local_tempdir()
output_dir_idx <- 1

lf$sink_batches(
  \(df) {
     # `df` is one chunk of the original LazyFrame.
     dest <- paste0(output_dir, "/file_", output_dir_idx, ".csv")
     cat(sprintf("Writing \%s rows to \%s\n", nrow(df), dest))
     write.csv(as.data.frame(df), dest)
     output_dir_idx <<- output_dir_idx + 1
  }
)

list.files(output_dir)

pl$read_csv(output_dir)

# The number of rows in each chunk can be adjusted with `chunk_size`.
output_dir <- withr::local_tempdir()
output_dir_idx <- 1

lf$sink_batches(
  \(df) {
     dest <- paste0(output_dir, "/file_", output_dir_idx, ".csv")
     cat(sprintf("Writing \%s rows to \%s\n", nrow(df), dest))
     write.csv(as.data.frame(df), dest)
     output_dir_idx <<- output_dir_idx + 1
  },
  chunk_size = 10
)

list.files(output_dir)

# To avoid manually creating paths and incrementing `output_dir_idx` in the
# anonymous function, we can use function factories:
output_dir <- withr::local_tempdir()
writer_factory <- function(dir) {
  i <- 0
  function(df) {
    i <<- i + 1
    as.data.frame(df) |>
      write.csv(file.path(dir, sprintf("\%03d.csv", i)), row.names = FALSE)
  }
}
writer <- writer_factory(output_dir)

lf$sink_batches(
  \(df) {
     cat(sprintf("Write \%s rows\n", nrow(df)))
     writer(df)
  },
  chunk_size = 10
)

list.files(output_dir)
}
