% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/io_ipc.R
\name{pl_scan_ipc}
\alias{pl_scan_ipc}
\title{Lazily read from an Arrow IPC (Feather v2) file or multiple files via glob patterns}
\usage{
pl_scan_ipc(
  source,
  ...,
  n_rows = NULL,
  memory_map = TRUE,
  row_index_name = NULL,
  row_index_offset = 0L,
  rechunk = FALSE,
  cache = TRUE,
  hive_partitioning = NULL,
  hive_schema = NULL,
  try_parse_hive_dates = TRUE,
  include_file_paths = NULL
)
}
\arguments{
\item{source}{Path to a file. You can use globbing with \code{*} to scan/read multiple
files in the same directory (see examples).}

\item{...}{Ignored.}

\item{n_rows}{Maximum number of rows to read.}

\item{memory_map}{A logical. If \code{TRUE}, try to memory map the file.
This can greatly improve performance on repeated queries as the OS may cache pages.
Only uncompressed Arrow IPC files can be memory mapped.}

\item{row_index_name}{If not \code{NULL}, this will insert a row index column with
the given name into the DataFrame.}

\item{row_index_offset}{Offset to start the row index column (only used if
the name is set).}

\item{rechunk}{In case of reading multiple files via a glob pattern, rechunk
the final DataFrame into contiguous memory chunks.}

\item{cache}{Cache the result after reading.}

\item{hive_partitioning}{Infer statistics and schema from Hive partitioned URL
and use them to prune reads. If \code{NULL} (default), it is automatically
enabled when a single directory is passed, and otherwise disabled.}

\item{hive_schema}{A list containing the column names and data types of the
columns by which the data is partitioned, e.g.
\code{list(a = pl$String, b = pl$Float32)}. If \code{NULL} (default), the schema of
the Hive partitions is inferred.}

\item{try_parse_hive_dates}{Whether to try parsing hive values as date/datetime
types.}

\item{include_file_paths}{Character value indicating the column name that will
include the path of the source file(s).}
}
\value{
\link[=LazyFrame_class]{LazyFrame}
}
\description{
This allows the query optimizer to push down predicates and projections to the scan level,
thereby potentially reducing memory overhead.
}
\details{
Hive-style partitioning is not supported yet.
}
\examples{
\dontshow{if (requireNamespace("arrow", quietly = TRUE) && arrow::arrow_with_dataset()) (if (getRversion() >= "3.4") withAutoprint else force)(\{ # examplesIf}
temp_dir = tempfile()
# Write a hive-style partitioned arrow file dataset
arrow::write_dataset(
  mtcars,
  temp_dir,
  partitioning = c("cyl", "gear"),
  format = "arrow",
  hive_style = TRUE
)
list.files(temp_dir, recursive = TRUE)

# If the path is a folder, Polars automatically tries to detect partitions
# and includes them in the output
pl$scan_ipc(temp_dir)$collect()

# We can also impose a schema to the partition
pl$scan_ipc(temp_dir, hive_schema = list(cyl = pl$String, gear = pl$Int32))$collect()
\dontshow{\}) # examplesIf}
}
