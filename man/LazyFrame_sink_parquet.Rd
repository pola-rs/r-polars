% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/lazyframe__lazy.R
\name{LazyFrame_sink_parquet}
\alias{LazyFrame_sink_parquet}
\title{LazyFrame stream output to parquet file}
\usage{
LazyFrame_sink_parquet(
  path,
  compression = "zstd",
  compression_level = 3,
  statistics = FALSE,
  row_group_size = NULL,
  data_pagesize_limit = NULL,
  maintain_order = TRUE,
  type_coercion = TRUE,
  predicate_pushdown = TRUE,
  projection_pushdown = TRUE,
  simplify_expression = TRUE,
  slice_pushdown = TRUE,
  no_optimization = FALSE
)
}
\arguments{
\item{path}{String. The path of the parquet file}

\item{compression}{String. The compression method. One of
\code{c('uncompressed', 'snappy', 'gzip', 'lzo', 'brotli', 'zstd')}
Choose “zstd” for good compression performance. Choose “lz4” for fast compression/decompression.
Choose “snappy” for more backwards compatibility guarantees when you deal with older parquet
readers.}

\item{compression_level}{NULL or Integer. Only used if method is one of
\verb{c('gzip', 'brotli', 'zstd'}. The level of compression to use. Higher compression means smaller
files on disk. “gzip” : min-level: 0, max-level: 10. “brotli” : min-level: 0, max-level: 11.
“zstd” : min-level: 1, max-level: 22.}

\item{statistics}{Boolean. Whether compute and write column statistics.
This requires extra compute.}

\item{row_group_size}{NULL or Integer. Size of the row groups in number of rows. If NULL
(default), the chunks of the DataFrame are used. Writing in smaller chunks may reduce memory
pressure and improve writing speeds.}

\item{data_pagesize_limit}{NULL or Integer. If set NULL the limit will be ~1MB.}

\item{maintain_order}{Boolean. Whether maintain the order the data was processed.
Setting this to False will be slightly faster.}

\item{type_coercion}{Boolean. Coerce types such that operations succeed and
run on minimal required memory.}

\item{predicate_pushdown}{Boolean. Applies filters as early as possible at
scan level.}

\item{projection_pushdown}{Boolean. Select only the columns that are needed at the scan level.}

\item{simplify_expression}{Boolean. Various optimizations, such as constant folding
and replacing expensive operations with faster alternatives.}

\item{slice_pushdown}{Boolean. Only load the required slice from the scan
Don't materialize sliced outputs
level. Don't materialize sliced outputs (e.g. \code{join$head(10)}).}

\item{no_optimization}{Boolean. Turn off the following optimizations:
predicate_pushdown = FALSE
projection_pushdown = FALSE
slice_pushdown = FALSE
common_subplan_elimination = FALSE}
}
\description{
Persists a LazyFrame at the provided path.
This allows streaming results that are larger than RAM to be written to disk.
}
\examples{
# sink table 'mtcars' from mem to parquet
tmpf = tempfile()
pl$LazyFrame(mtcars)$sink_parquet(tmpf)

# stream a query end-to-end
tmpf2 = tempfile()
pl$scan_parquet(tmpf)$select(pl$col("cyl") * 2)$sink_parquet(tmpf2)

# load parquet directly into a DataFrame / memory
pl$scan_parquet(tmpf2)$collect()
}
