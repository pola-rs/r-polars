% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/output-csv.R
\name{lazyframe__sink_csv}
\alias{lazyframe__sink_csv}
\alias{lazyframe__lazy_sink_csv}
\title{Evaluate the query in streaming mode and write to a CSV file}
\usage{
lazyframe__sink_csv(
  path,
  ...,
  include_bom = FALSE,
  include_header = TRUE,
  separator = ",",
  line_terminator = "\\n",
  quote_char = "\\"",
  batch_size = 1024,
  datetime_format = NULL,
  date_format = NULL,
  time_format = NULL,
  float_scientific = NULL,
  float_precision = NULL,
  decimal_comma = FALSE,
  null_value = "",
  quote_style = c("necessary", "always", "never", "non_numeric"),
  maintain_order = TRUE,
  storage_options = NULL,
  retries = 2,
  sync_on_close = c("none", "data", "all"),
  mkdir = FALSE,
  engine = c("auto", "in-memory", "streaming"),
  optimizations = QueryOptFlags()
)

lazyframe__lazy_sink_csv(
  path,
  ...,
  include_bom = FALSE,
  include_header = TRUE,
  separator = ",",
  line_terminator = "\\n",
  quote_char = "\\"",
  batch_size = 1024,
  datetime_format = NULL,
  date_format = NULL,
  time_format = NULL,
  float_scientific = NULL,
  float_precision = NULL,
  decimal_comma = FALSE,
  null_value = "",
  quote_style = c("necessary", "always", "never", "non_numeric"),
  maintain_order = TRUE,
  storage_options = NULL,
  retries = 2,
  sync_on_close = c("none", "data", "all"),
  mkdir = FALSE
)
}
\arguments{
\item{path}{A character. File path to which the file should be written.}

\item{...}{These dots are for future extensions and must be empty.}

\item{include_bom}{Logical, whether to include UTF-8 BOM in the CSV output.}

\item{include_header}{Logical, whether to include header in the CSV output.}

\item{separator}{Separate CSV fields with this symbol.}

\item{line_terminator}{String used to end each row.}

\item{quote_char}{Byte to use as quoting character.}

\item{batch_size}{Number of rows that will be processed per thread.}

\item{datetime_format}{A format string, with the specifiers defined by the
\href{https://docs.rs/chrono/latest/chrono/format/strftime/index.html}{chrono}
Rust crate. If no format specified, the default fractional-second precision
is inferred from the maximum timeunit found in the frameâ€™s Datetime cols (if
any).}

\item{date_format}{A format string, with the specifiers defined by the
\href{https://docs.rs/chrono/latest/chrono/format/strftime/index.html}{chrono}
Rust crate.}

\item{time_format}{A format string, with the specifiers defined by the
\href{https://docs.rs/chrono/latest/chrono/format/strftime/index.html}{chrono}
Rust crate.}

\item{float_scientific}{Whether to use scientific form always (\code{TRUE}),
never (\code{FALSE}), or automatically (\code{NULL}) for Float32 and Float64 datatypes.}

\item{float_precision}{Number of decimal places to write, applied to both
Float32 and Float64 datatypes.}

\item{decimal_comma}{If \code{TRUE}, use a comma \code{","} as the decimal separator
instead of a point. Floats will be encapsulated in quotes if necessary.}

\item{null_value}{A string representing null values (defaulting to the empty
string).}

\item{quote_style}{Determines the quoting strategy used. Must be one of:
\itemize{
\item \code{"necessary"} (default): This puts quotes around fields only when
necessary. They are necessary when fields contain a quote, delimiter or
record terminator. Quotes are also necessary when writing an empty record
(which is indistinguishable from a record with one empty field). This is
the default.
\item \code{"always"}: This puts quotes around every field. Always.
\item \code{"never"}: This never puts quotes around fields, even if that results in
invalid CSV data (e.g.: by not quoting strings containing the separator).
\item \code{"non_numeric"}: This puts quotes around all fields that are non-numeric.
Namely, when writing a field that does not parse as a valid float or
integer, then quotes will be used even if they aren`t strictly necessary.
}}

\item{maintain_order}{Maintain the order in which data is processed. Setting
this to \code{FALSE} will be slightly faster.}

\item{storage_options}{Named vector containing options that indicate how to
connect to a cloud provider. The cloud providers currently supported are
AWS, GCP, and Azure.
See supported keys here:
\itemize{
\item \href{https://docs.rs/object_store/latest/object_store/aws/enum.AmazonS3ConfigKey.html}{aws}
\item \href{https://docs.rs/object_store/latest/object_store/gcp/enum.GoogleConfigKey.html}{gcp}
\item \href{https://docs.rs/object_store/latest/object_store/azure/enum.AzureConfigKey.html}{azure}
\item Hugging Face (\verb{hf://}): Accepts an API key under the token parameter
\code{c(token = YOUR_TOKEN)} or by setting the \code{HF_TOKEN} environment
variable.
}

If \code{storage_options} is not provided, Polars will try to infer the
information from environment variables.}

\item{retries}{Number of retries if accessing a cloud instance fails.}

\item{sync_on_close}{Sync to disk when before closing a file. Must be one of:
\itemize{
\item \code{"none"}: does not sync;
\item \code{"data"}: syncs the file contents;
\item \code{"all"}: syncs the file contents and metadata.
}}

\item{mkdir}{Recursively create all the directories in the path.}

\item{engine}{The engine name to use for processing the query.
One of the followings:
\itemize{
\item \code{"auto"} (default): Select the engine automatically.
The \code{"in-memory"} engine will be selected for most cases.
\item \code{"in-memory"}: Use the in-memory engine.
\item \code{"streaming"}: \ifelse{html}{\href{https://lifecycle.r-lib.org/articles/stages.html#experimental}{\figure{lifecycle-experimental.svg}{options: alt='[Experimental]'}}}{\strong{[Experimental]}} Use the (new) streaming engine.
}}

\item{optimizations}{\ifelse{html}{\href{https://lifecycle.r-lib.org/articles/stages.html#experimental}{\figure{lifecycle-experimental.svg}{options: alt='[Experimental]'}}}{\strong{[Experimental]}}
A \link{QueryOptFlags} object to indicate optimization passes done during query optimization.}
}
\value{
\itemize{
\item \verb{<lazyframe>$sink_*()} returns \code{NULL} invisibly.
\item \verb{<lazyframe>$lazy_sink_*()} returns a new \link{LazyFrame}.
}
}
\description{
\ifelse{html}{\href{https://lifecycle.r-lib.org/articles/stages.html#experimental}{\figure{lifecycle-experimental.svg}{options: alt='[Experimental]'}}}{\strong{[Experimental]}}

This allows streaming results that are larger than RAM to be written to disk.
\itemize{
\item \verb{<lazyframe>$lazy_sink_*()} don't write directly to the output file(s) until
\code{\link[=lazyframe__collect]{$collect()}} is called.
This is useful if you want to save a query to review or run later.
\item \verb{<lazyframe>$sink_*()} write directly to the output file(s) (they are shortcuts for
\verb{<lazyframe>$lazy_sink_*()$collect()}).
}
}
\examples{
# Sink table 'mtcars' from mem to CSV
tmpf <- tempfile(fileext = ".csv")
as_polars_lf(mtcars)$sink_csv(tmpf)

# Create a query that can be run in streaming end-to-end
tmpf2 <- tempfile(fileext = ".csv")
lf <- pl$scan_csv(tmpf)$select(pl$col("cyl") * 2)$lazy_sink_csv(tmpf2)
lf$explain() |>
  cat()

# Execute the query and write to disk
lf$collect()

# Load CSV directly into a DataFrame / memory
pl$read_csv(tmpf2)
}
