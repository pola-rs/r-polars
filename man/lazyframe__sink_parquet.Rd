% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/lazyframe-utils.R, R/output-parquet-functions.R
\name{parquet_statistics}
\alias{parquet_statistics}
\alias{lazyframe__sink_parquet}
\title{Evaluate the query in streaming mode and write to a Parquet file}
\usage{
parquet_statistics(
  ...,
  min = TRUE,
  max = TRUE,
  distinct_count = TRUE,
  null_count = TRUE
)

lazyframe__sink_parquet(
  path,
  ...,
  compression = c("lz4", "uncompressed", "snappy", "gzip", "lzo", "brotli", "zstd"),
  compression_level = NULL,
  statistics = TRUE,
  row_group_size = NULL,
  data_page_size = NULL,
  maintain_order = TRUE,
  type_coercion = TRUE,
  `_type_check` = TRUE,
  predicate_pushdown = TRUE,
  projection_pushdown = TRUE,
  simplify_expression = TRUE,
  slice_pushdown = TRUE,
  collapse_joins = TRUE,
  no_optimization = FALSE,
  storage_options = NULL,
  retries = 2,
  sync_on_close = c("none", "data", "all"),
  mkdir = FALSE
)
}
\arguments{
\item{...}{These dots are for future extensions and must be empty.}

\item{min}{Include stats on the minimum values in the column.}

\item{max}{Include stats on the maximum values in the column.}

\item{distinct_count}{Include stats on the number of distinct values in the
column.}

\item{null_count}{Include stats on the number of null values in the column.}

\item{path}{A character. File path to which the file should be written.}

\item{compression}{The compression method. Must be one of:
\itemize{
\item \code{"lz4"}: fast compression/decompression.
\item \code{"uncompressed"}
\item \code{"snappy"}: this guarantees that the parquet file will be compatible with
older parquet readers.
\item \code{"gzip"}
\item \code{"lzo"}
\item \code{"brotli"}
\item \code{"zstd"}: good compression performance.
}}

\item{compression_level}{\code{NULL} or integer. The level of compression to use.
Only used if method is one of \code{"gzip"}, \code{"brotli"}, or \code{"zstd"}. Higher
compression means smaller files on disk:
\itemize{
\item \code{"gzip"}: min-level: 0, max-level: 10.
\item \code{"brotli"}: min-level: 0, max-level: 11.
\item \code{"zstd"}: min-level: 1, max-level: 22.
}}

\item{statistics}{Whether statistics should be written to the Parquet
headers. Possible values:
\itemize{
\item \code{TRUE}: enable default set of statistics (default). Some statistics may be
disabled.
\item \code{FALSE}: disable all statistics
\item \code{"full"}: calculate and write all available statistics
\item A list created via \code{\link[=parquet_statistics]{parquet_statistics()}} to specify which statistics to
include.
}}

\item{row_group_size}{Size of the row groups in number of rows. If \code{NULL}
(default), the chunks of the DataFrame are used. Writing in smaller chunks
may reduce memory pressure and improve writing speeds.}

\item{data_page_size}{Size of the data page in bytes. If \code{NULL} (default), it
is set to 1024^2 bytes.}

\item{maintain_order}{Maintain the order in which data is processed. Setting
this to \code{FALSE} will be slightly faster.}

\item{type_coercion}{A logical, indicats type coercion optimization.}

\item{predicate_pushdown}{A logical, indicats predicate pushdown optimization.}

\item{projection_pushdown}{A logical, indicats projection pushdown optimization.}

\item{simplify_expression}{A logical, indicats simplify expression optimization.}

\item{slice_pushdown}{A logical, indicats slice pushdown optimization.}

\item{collapse_joins}{Collapse a join and filters into a faster join.}

\item{no_optimization}{A logical. If \code{TRUE}, turn off (certain) optimizations.}

\item{storage_options}{Named vector containing options that indicate how to
connect to a cloud provider. The cloud providers currently supported are
AWS, GCP, and Azure.
See supported keys here:
\itemize{
\item \href{https://docs.rs/object_store/latest/object_store/aws/enum.AmazonS3ConfigKey.html}{aws}
\item \href{https://docs.rs/object_store/latest/object_store/gcp/enum.GoogleConfigKey.html}{gcp}
\item \href{https://docs.rs/object_store/latest/object_store/azure/enum.AzureConfigKey.html}{azure}
\item Hugging Face (\verb{hf://}): Accepts an API key under the token parameter
\code{c(token = YOUR_TOKEN)} or by setting the \code{HF_TOKEN} environment
variable.
}

If \code{storage_options} is not provided, Polars will try to infer the
information from environment variables.}

\item{retries}{Number of retries if accessing a cloud instance fails.}
}
\value{
Invisibly returns the input LazyFrame
}
\description{
\ifelse{html}{\href{https://lifecycle.r-lib.org/articles/stages.html#experimental}{\figure{lifecycle-experimental.svg}{options: alt='[Experimental]'}}}{\strong{[Experimental]}}

This allows streaming results that are larger than RAM to be written to disk.
}
\examples{
# sink table 'mtcars' from mem to parquet
tmpf <- tempfile()
as_polars_lf(mtcars)$sink_parquet(tmpf)

# stream a query end-to-end
tmpf2 <- tempfile()
pl$scan_parquet(tmpf)$select(pl$col("cyl") * 2)$sink_parquet(tmpf2)

# load parquet directly into a DataFrame / memory
pl$scan_parquet(tmpf2)$collect()
}
