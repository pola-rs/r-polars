% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/expr__expr.R
\name{Expr_map_elements}
\alias{Expr_map_elements}
\title{Map a custom/user-defined function (UDF) to each element of a column}
\usage{
Expr_map_elements(
  f,
  return_type = NULL,
  strict_return_type = TRUE,
  allow_fail_eval = FALSE,
  in_background = FALSE
)
}
\arguments{
\item{f}{Function to map}

\item{return_type}{DataType of the output Series. If \code{NULL}, the dtype will
be \code{pl$Unknown}.}

\item{strict_return_type}{If \code{TRUE} (default), error if not correct datatype
returned from R. If \code{FALSE}, the output will be converted to a polars null
value.}

\item{allow_fail_eval}{If \code{FALSE} (default), raise an error if the function
fails. If \code{TRUE}, the result will be converted to a polars null value.}

\item{in_background}{Whether to run the function in a background R process,
default is \code{FALSE}. Combined with setting e.g. \code{pl$set_options(rpool_cap = 4)},
this can speed up some slow R functions as they can run in parallel R sessions.
The communication speed between processes is quite slower than between threads.
This will likely only give a speed-up in a "low IO - high CPU" usecase. A
single map will not be paralleled, only in case of multiple \verb{$map_elements()}
in the query can these run in parallel.}
}
\value{
Expr
}
\description{
The UDF is applied to each element of a column. See Details for more information
on specificities related to the context.
}
\details{
Note that, in a GroupBy context, the column will have been pre-aggregated and
so each element will itself be a Series. Therefore, depending on the context,
requirements for function differ:
\itemize{
\item in \verb{$select()} or \verb{$with_columns()} (selection context), the function must
operate on R scalar values. Polars will convert each element into an R value
and pass it to the function. The output of the user function will be converted
back into a polars type (the return type must match, see argument \code{return_type}).
Using \verb{$map_elements()} in this context should be avoided as a \code{lapply()}
has half the overhead.
\item in \verb{$agg()} (GroupBy context), the function must take a \code{Series} and return
a \code{Series} or an R object convertible to \code{Series}, e.g. a vector. In this
context, it is much faster if there are the number of groups is much lower
than the number of rows, as the iteration is only across the groups. The R
user function could e.g. convert the \code{Series} to a vector with \verb{$to_r()} and
perform some vectorized operations.
}

Note that it is preferred to express your function in polars syntax, which
will almost always be \emph{significantly} faster and more memory efficient because:
\itemize{
\item the native expression engine runs in Rust; functions run in R.
\item use of R functions forces the DataFrame to be materialized in memory.
\item Polars-native expressions can be parallelized (R functions cannot).
\item Polars-native expressions can be logically optimized (R functions cannot).
}

Wherever possible you should strongly prefer the native expression API to
achieve the best performance and avoid using \verb{$map_elements()}.
}
\examples{
# apply over groups: here, the input must be a Series
# prepare two expressions, one to compute the sum of each variable, one to
# get the first two values of each variable and store them in a list
e_sum = pl$all()$map_elements(\(s) sum(s$to_r()))$name$suffix("_sum")
e_head = pl$all()$map_elements(\(s) head(s$to_r(), 2))$name$suffix("_head")
pl$DataFrame(iris)$group_by("Species")$agg(e_sum, e_head)

# apply a function on each value (should be avoided): here the input is an R
# scalar
# select only Float64 columns
my_selection = pl$col(pl$dtypes$Float64)

# prepare two expressions, the first one only adds 10 to each element, the
# second returns the letter whose index matches the element
e_add10 = my_selection$map_elements(\(x)  {
  x + 10
})$name$suffix("_sum")

e_letter = my_selection$map_elements(\(x) {
  letters[ceiling(x)]
}, return_type = pl$dtypes$Utf8)$name$suffix("_letter")
pl$DataFrame(iris)$select(e_add10, e_letter)


# Small benchmark --------------------------------

# Using `$map_elements()` is much slower than a more polars-native approach.
# First we multiply each element of a Series of 1M elements by 2.
n = 1000000L
set.seed(1)
df = pl$DataFrame(list(
  a = 1:n,
  b = sample(letters, n, replace = TRUE)
))

system.time({
  df$with_columns(
    bob = pl$col("a")$map_elements(\(x) {
      x * 2L
    })
  )
})

# Comparing this to the standard polars syntax:
system.time({
  df$with_columns(
    bob = pl$col("a") * 2L
  )
})


# Running in parallel --------------------------------

# here, we use Sys.sleep() to imitate some CPU expensive computation.

# use apply over each Species-group in each column equal to 12 sequential
# runs ~1.2 sec.
system.time({
  pl$LazyFrame(iris)$group_by("Species")$agg(
    pl$all()$map_elements(\(s) {
      Sys.sleep(.1)
      s$sum()
    })
  )$collect()
})

# first run in parallel: there is some overhead to start up extra R processes
# drop any previous processes, just to show start-up overhead here
pl$set_options(rpool_cap = 0)
# set back to 4, the default
pl$set_options(rpool_cap = 4)
pl$options$rpool_cap

system.time({
  pl$LazyFrame(iris)$group_by("Species")$agg(
    pl$all()$map_elements(\(s) {
      Sys.sleep(.1)
      s$sum()
    }, in_background = TRUE)
  )$collect()
})

# second run in parallel: this reuses R processes in "polars global_rpool".
pl$options$rpool_cap
system.time({
  pl$LazyFrame(iris)$group_by("Species")$agg(
    pl$all()$map_elements(\(s) {
      Sys.sleep(.1)
      s$sum()
    }, in_background = TRUE)
  )$collect()
})
}
