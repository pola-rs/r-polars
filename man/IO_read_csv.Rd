% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/csv.R
\name{read_csv}
\alias{read_csv}
\title{New DataFrame from CSV}
\arguments{
\item{path}{Path to a file or URL. It is possible to provide multiple paths
provided that all CSV files have the same schema. It is not possible to
provide several URLs.}

\item{has_header}{Indicate if the first row of dataset is a header or not.If
\code{FALSE}, column names will be autogenerated in the following format: \code{"column_x"}
\code{x} being an enumeration over every column in the dataset starting at 1.}

\item{separator}{Single byte character to use as separator in the file.}

\item{comment_char}{Single byte character that indicates the start of a comment
line, for instance \verb{#}.}

\item{quote_char}{Single byte character used for quoting. Set to \code{NULL} to
turn off special handling and escaping of quotes.}

\item{skip_rows}{Start reading after a particular number of rows. The header
will be parsed at this offset.}

\item{dtypes}{Named list of column names - dtypes or dtype - column names. This
list is used while reading to overwrite dtypes. Supported types so far are:
\itemize{
\item "Boolean" or "logical" for DataType::Boolean,
\item "Categorical" or "factor" for DataType::Categorical,
\item "Float32" or "double" for DataType::Float32,
\item "Float64" or "float64" for DataType::Float64,
\item "Int32" or "integer" for DataType::Int32,
\item "Int64" or "integer64" for DataType::Int64,
\item "Utf8" or "character" for DataType::Utf8,
}}

\item{null_values}{Values to interpret as \code{NA} values. Can be:
\itemize{
\item a string : all values equal to this string will be \code{NA};
\item an unnamed character vector that matches the number of columns: the \code{n}th
value will be replaced by \code{NA} in the \code{n}th column;
\item a named character vector with column names and null values.
}}

\item{missing_utf8_is_empty_string}{By default, a missing value is considered
to be \code{NA}. Setting this parameter to \code{TRUE} will consider missing UTF8 values
as an empty character.}

\item{ignore_errors}{Keep reading the file even if some lines yield errors.
You can also use \code{infer_schema_length = 0} to read all columns as UTF8 to
check which values might cause an issue.}

\item{cache}{Cache the result after reading.}

\item{infer_schema_length}{Maximum number of rows to read to infer the column
types. If set to 0, all columns will be read as UTF-8. If \code{NULL}, a full
table scan will be done (slow).}

\item{n_rows}{Maximum number of rows to read.}

\item{encoding}{Either \code{"utf8"} or \code{"utf8-lossy"}. Lossy means that invalid
UTF8 values are replaced with "?" characters.}

\item{low_memory}{Reduce memory usage (will yield a lower performance).}

\item{rechunk}{Reallocate to contiguous memory when all chunks / files are
parsed.}

\item{skip_rows_after_header}{Parse the first row as headers, and then skip
this number of rows.}

\item{try_parse_dates}{Try to automatically parse dates. Most ISO8601-like
formats can be inferred, as well as a handful of others. If this does not
succeed, the column remains of data type \code{pl$Utf8}.}

\item{eol_char}{Single byte end of line character (default: \verb{\\n}). When
encountering a file with Windows line endings (\verb{\\r\\n}), one can go with the
default \verb{\\n}. The extra \verb{\\r} will be removed when processed.}

\item{raise_if_empty}{If \code{FALSE}, parsing an empty file returns an empty
DataFrame or LazyFrame.}

\item{truncate_ragged_lines}{Truncate lines that are longer than the schema.}

\item{reuse_downloaded}{If \code{TRUE}(default) and a URL was provided, cache the
downloaded files in session for an easy reuse.}
}
\value{
DataFrame
}
\description{
Read a file from path into a polars DataFrame.
}
